# Large Language Models with Hugging Face — Video Outline

---

## Module 1: Introduction to LLM Interactions

**Description:** Explore foundational concepts of interacting with LLMs using Hugging Face. Learn to navigate the Hub, deploy models locally, and master prompt engineering for real-world applications.

**Learning Objectives:**
- Understand the Hugging Face ecosystem and deploy your first model
- Master prompt engineering and system design
- Control LLM outputs and manage conversations effectively

### Lesson 1.1: Getting Started with Hugging Face

| Filename | Title |
|----------|-------|
| `1.1-why-hugging-face-llm-interactions-matter.mp4` | Why Hugging Face & LLM Interactions Matter |
| `1.2-running-llm-locally-transformers.mp4` | Running an LLM Locally with Transformers (Screencast) |

### Lesson 1.2: Prompt Engineering Fundamentals

| Filename | Title |
|----------|-------|
| `1.3-prompt-engineering-patterns.mp4` | Prompt Engineering Patterns: Instructions, Few-Shot, Chain-of-Thought |

---

## Module 2: Enhancing LLMs with Knowledge and Tools

**Description:** Enhance LLM capabilities with knowledge augmentation and tool integration. Create vector knowledge bases, implement RAG, and extend LLMs with function calling.

**Learning Objectives:**
- Create a vector knowledge base and understand knowledge-augmented LLMs
- Implement the Retrieval-Augmented Generation (RAG) API
- Extend LLMs with tools and function calling

### Lesson 2.1: Knowledge Augmentation & RAG

| Filename | Title |
|----------|-------|
| `2.1-why-knowledge-augmented-tool-enabled-llms-matter.mp4` | Why Knowledge-Augmented and Tool-Enabled LLMs Matter |
| `2.2-generating-embeddings-custom-dataset.mp4` | Generating Embeddings for Your Custom Dataset |
| `2.3-introduction-rag-architecture.mp4` | Introduction to RAG Architecture |
| `2.4-challenges-evaluation-knowledge-augmented-systems.mp4` | Challenges, Evaluation, and Next Steps for Knowledge-Augmented Systems |

### Lesson 2.2: Tool Integration & Function Calling

| Filename | Title |
|----------|-------|
| `2.5-introduction-tool-enabled-llms.mp4` | Introduction to Tool-Enabled LLMs |
| `2.6-implementing-ollama-function-calling-interface.mp4` | Implementing an Ollama-Compatible Function Calling Interface |

---

## Module 3: Creating Agentic Systems and Deployment Strategies

**Description:** Build agentic LLM systems and deploy them effectively. Learn reusable agent patterns, LangChain integration, and Hugging Face inferencing strategies.

**Learning Objectives:**
- Develop agentic LLM systems using reusable patterns
- Understand Hugging Face inferencing and pricing models

### Lesson 3.1: Building Agentic Systems

| Filename | Title |
|----------|-------|
| `3.1-why-agentic-llm-systems-deployment-strategies-matter.mp4` | Why Agentic LLM Systems and Deployment Strategies Matter |
| `3.2-building-simple-agentic-flow.mp4` | Demonstration: Building a Simple Agentic Flow (Screencast) |

### Lesson 3.2: Deployment with LangChain & Hugging Face

| Filename | Title |
|----------|-------|
| `3.3-langchain-patterns-hugging-face-inferencing.mp4` | Walkthrough: LangChain Patterns with Hugging Face Inferencing |

---

## Module 4: Capstone

**Description:** Apply all course concepts to build a production-ready AI-powered research assistant combining RAG, agents, and API development.

**Learning Objectives:**
- Integrate multiple LLM capabilities into a cohesive application
- Design and implement a production-ready RAG pipeline with agentic workflows

### Lesson 4.1: Capstone Project

| Filename | Title | Type |
|----------|-------|------|
| `capstone-project.md` | Capstone Project: AI-Powered Research Assistant | Reading |
| — | Final Exam | Graded Assignment |

---

**Total: 12 videos** across 3 content modules
